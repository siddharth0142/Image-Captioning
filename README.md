# Image-Captioning

Image captioning has always been a great source of help for visually impaired by generating captions for the given image. But limiting it to the captions won't be that helpful for the visually challenged. In this project we tried to give voice to our generated captions by using the concept for TTS that is text-to-speech which is more impactful and practical. To accomplish caption generation and to implement Deep learning architecture we have used Tensorflow and Keras. it is challenging to generate captions that have right linguistic properties because it requires sophisticated level of image understanding. In this project, we used VGG16 deep learning architecture for the purpose of feature extraction for the images. The generated caption's quality and accuracy are evaluated using BLEU score
KEYWORDS: Image captioning, Deep Learning, Neural Networks, Text-to-speech, BLEU Score.


![image](https://github.com/user-attachments/assets/361f2f5a-a425-4e24-a16b-4302ce4fc117)
